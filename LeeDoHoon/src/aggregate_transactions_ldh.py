"""
KKBox Transactions ì§‘ê³„ (ìƒíƒœ + ëˆ„ì  ì¤‘ì‹¬)
ì‘ì„±ì: ì´ë„í›ˆ (LDH)
ì‘ì„±ì¼: 2025-12-16

kkbox_aggregation_plan.md ê¸°ì¤€ìœ¼ë¡œ ì§‘ê³„:
- ìƒíƒœ ê¸°ë°˜ í”¼ì²˜ (ë§ˆì§€ë§‰ ê±°ë˜ ê¸°ì¤€)
- ëˆ„ì  íˆìŠ¤í† ë¦¬ í”¼ì²˜ (ì „ì²´ ê¸°ê°„)
- ì œí•œì  Recency ì§‘ê³„ (30ì¼, 90ì¼)
- ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€: T = 2017-03-31 ì´ì „ë§Œ ì‚¬ìš©
"""

import pandas as pd
import numpy as np
from pathlib import Path
from typing import Optional
import warnings

warnings.filterwarnings('ignore')

# ============================================
# ì„¤ì •
# ============================================
T = pd.Timestamp('2017-03-31')  # ê¸°ì¤€ ì‹œì 

DATA_DIR = Path(__file__).parent.parent / 'data'


# ============================================
# ì§‘ê³„ í•¨ìˆ˜
# ============================================
def load_transactions(data_dir: Path = DATA_DIR) -> pd.DataFrame:
    """transactions_v2.csv ë¡œë“œ ë° ì „ì²˜ë¦¬"""
    print("ğŸ“‚ transactions_v2.csv ë¡œë“œ ì¤‘...")
    
    df = pd.read_csv(data_dir / 'transactions_v2.csv')
    print(f"  âœ“ ì›ë³¸: {df.shape}")
    
    # ë‚ ì§œ ë³€í™˜
    df['transaction_date'] = pd.to_datetime(df['transaction_date'], format='%Y%m%d')
    df['membership_expire_date'] = pd.to_datetime(df['membership_expire_date'], format='%Y%m%d')
    
    # T ì´ì „ ë°ì´í„°ë§Œ ì‚¬ìš© (ë°ì´í„° ëˆ„ìˆ˜ ë°©ì§€)
    df = df[df['transaction_date'] <= T].copy()
    
    print(f"  âœ“ T ì´ì „ í•„í„°ë§ í›„: {df.shape}")
    print(f"  âœ“ ë‚ ì§œ ë²”ìœ„: {df['transaction_date'].min().strftime('%Y-%m-%d')} ~ {df['transaction_date'].max().strftime('%Y-%m-%d')}")
    print(f"  âœ“ ê³ ìœ  ì‚¬ìš©ì: {df['msno'].nunique():,}")
    
    return df


def create_state_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    ìƒíƒœ ê¸°ë°˜ í”¼ì²˜ (ë§ˆì§€ë§‰ ê±°ë˜ ê¸°ì¤€)
    - ê°€ì¥ ì¤‘ìš”í•œ í”¼ì²˜ë“¤
    """
    print("\nğŸ“Š ìƒíƒœ ê¸°ë°˜ í”¼ì²˜ ìƒì„± ì¤‘...")
    
    # ì‚¬ìš©ìë³„ ìµœì‹  ê±°ë˜ ì¶”ì¶œ
    df_sorted = df.sort_values(['msno', 'transaction_date'], ascending=[True, False])
    latest = df_sorted.groupby('msno').first().reset_index()
    
    # ìƒíƒœ í”¼ì²˜ ìƒì„±
    features = pd.DataFrame()
    features['msno'] = latest['msno']
    
    # ë§ˆì§€ë§‰ ê²°ì œ í›„ ê²½ê³¼ì¼
    features['days_since_last_payment'] = (T - latest['transaction_date']).dt.days
    
    # ë§ˆì§€ë§‰ ê±°ë˜ ì •ë³´
    features['is_auto_renew_last'] = latest['is_auto_renew']
    features['last_plan_days'] = latest['payment_plan_days']
    features['last_payment_method'] = latest['payment_method_id']
    features['last_amount_paid'] = latest['actual_amount_paid']
    features['last_list_price'] = latest['plan_list_price']
    
    # ë§ˆì§€ë§‰ ê±°ë˜ í• ì¸ìœ¨
    features['last_discount_rate'] = 1 - (features['last_amount_paid'] / (features['last_list_price'] + 1e-9))
    features['last_discount_rate'] = features['last_discount_rate'].clip(0, 1)
    
    # ë§Œë£Œê¹Œì§€ ë‚¨ì€ ì¼ìˆ˜ (T ê¸°ì¤€)
    features['days_to_expire'] = (latest['membership_expire_date'] - T).dt.days
    
    # ì´ë¯¸ ë§Œë£Œë¨ í”Œë˜ê·¸
    features['is_expired'] = (features['days_to_expire'] < 0).astype(int)
    
    # ë§ˆì§€ë§‰ ê±°ë˜ê°€ ì·¨ì†Œì¸ì§€
    features['is_last_cancel'] = latest['is_cancel']
    
    print(f"  âœ“ ìƒíƒœ í”¼ì²˜ {len(features.columns)-1}ê°œ ìƒì„±")
    
    return features


def create_history_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    ëˆ„ì  íˆìŠ¤í† ë¦¬ í”¼ì²˜ (ì „ì²´ ê¸°ê°„)
    - 2015-01-01 ~ 2017-03-31
    """
    print("\nğŸ“Š ëˆ„ì  íˆìŠ¤í† ë¦¬ í”¼ì²˜ ìƒì„± ì¤‘...")
    
    # í• ì¸ìœ¨ ê³„ì‚°
    df = df.copy()
    df['discount_rate'] = 1 - (df['actual_amount_paid'] / (df['plan_list_price'] + 1e-9))
    df['discount_rate'] = df['discount_rate'].clip(0, 1)
    
    # ì§‘ê³„
    agg_dict = {
        'transaction_date': 'count',           # ì´ ê±°ë˜ íšŸìˆ˜
        'actual_amount_paid': ['sum', 'mean'], # ì´/í‰ê·  ê²°ì œì•¡
        'is_cancel': 'sum',                    # ì·¨ì†Œ íšŸìˆ˜
        'is_auto_renew': 'mean',               # ìë™ê°±ì‹  ë¹„ìœ¨
        'payment_plan_days': ['mean', 'nunique'],  # í‰ê· /ê³ ìœ  í”Œëœ
        'payment_method_id': 'nunique',        # ê³ ìœ  ê²°ì œìˆ˜ë‹¨
        'discount_rate': 'mean',               # í‰ê·  í• ì¸ìœ¨
    }
    
    history = df.groupby('msno').agg(agg_dict)
    
    # ì»¬ëŸ¼ëª… ì •ë¦¬
    history.columns = [
        'total_payment_count',
        'total_amount_paid',
        'avg_amount_per_payment',
        'total_cancel_count',
        'auto_renew_rate_history',
        'avg_plan_days',
        'unique_plan_count',
        'unique_payment_method_count',
        'avg_discount_rate_history',
    ]
    
    history = history.reset_index()
    
    # ì¶”ê°€ íŒŒìƒ í”¼ì²˜
    # ì·¨ì†Œ ë¹„ìœ¨
    history['cancel_rate'] = history['total_cancel_count'] / (history['total_payment_count'] + 1e-9)
    
    # ì·¨ì†Œ ì´ë ¥ ìœ ë¬´
    history['has_cancelled'] = (history['total_cancel_count'] > 0).astype(int)
    
    # êµ¬ë… ê°œì›” ìˆ˜ ì¶”ì • (ì´ ê²°ì œ íšŸìˆ˜ ê¸°ë°˜)
    history['subscription_months_est'] = history['total_payment_count']
    
    print(f"  âœ“ íˆìŠ¤í† ë¦¬ í”¼ì²˜ {len(history.columns)-1}ê°œ ìƒì„±")
    
    return history


def create_recency_features(df: pd.DataFrame) -> pd.DataFrame:
    """
    ì œí•œì  Recency ì§‘ê³„ (30ì¼, 90ì¼)
    - 7ì¼, 14ì¼ì€ ëŒ€ë¶€ë¶„ 0ì´ë¯€ë¡œ ë¹„ê¶Œì¥
    """
    print("\nğŸ“Š Recency í”¼ì²˜ ìƒì„± ì¤‘...")
    
    features = pd.DataFrame({'msno': df['msno'].unique()})
    
    # ìµœê·¼ 30ì¼ (2017-03-01 ~ 2017-03-31)
    last_30d = df[df['transaction_date'] >= T - pd.Timedelta(days=30)]
    count_30d = last_30d.groupby('msno').size().reset_index(name='payment_count_last_30d')
    
    # ìµœê·¼ 90ì¼ (2017-01-01 ~ 2017-03-31)
    last_90d = df[df['transaction_date'] >= T - pd.Timedelta(days=90)]
    count_90d = last_90d.groupby('msno').size().reset_index(name='payment_count_last_90d')
    
    # ìµœê·¼ 180ì¼
    last_180d = df[df['transaction_date'] >= T - pd.Timedelta(days=180)]
    count_180d = last_180d.groupby('msno').size().reset_index(name='payment_count_last_180d')
    
    # ë³‘í•©
    features = features.merge(count_30d, on='msno', how='left')
    features = features.merge(count_90d, on='msno', how='left')
    features = features.merge(count_180d, on='msno', how='left')
    
    # ê²°ì¸¡ = 0
    features = features.fillna(0)
    
    # ìµœê·¼ ê²°ì œ ì§‘ì¤‘ë„
    features['recency_30d_90d_ratio'] = features['payment_count_last_30d'] / (features['payment_count_last_90d'] + 1e-9)
    
    print(f"  âœ“ Recency í”¼ì²˜ {len(features.columns)-1}ê°œ ìƒì„±")
    
    return features


def create_cancel_features(df: pd.DataFrame) -> pd.DataFrame:
    """ì·¨ì†Œ ê´€ë ¨ ìƒì„¸ í”¼ì²˜"""
    print("\nğŸ“Š ì·¨ì†Œ ê´€ë ¨ í”¼ì²˜ ìƒì„± ì¤‘...")
    
    # ì·¨ì†Œ ê±°ë˜ë§Œ í•„í„°ë§
    cancel_df = df[df['is_cancel'] == 1]
    
    if len(cancel_df) == 0:
        print("  âš ï¸ ì·¨ì†Œ ë°ì´í„° ì—†ìŒ")
        return pd.DataFrame({'msno': df['msno'].unique()})
    
    # ë§ˆì§€ë§‰ ì·¨ì†Œì¼
    last_cancel = cancel_df.groupby('msno')['transaction_date'].max().reset_index()
    last_cancel.columns = ['msno', 'last_cancel_date']
    last_cancel['days_since_last_cancel'] = (T - last_cancel['last_cancel_date']).dt.days
    
    features = last_cancel[['msno', 'days_since_last_cancel']]
    
    print(f"  âœ“ ì·¨ì†Œ í”¼ì²˜ {len(features.columns)-1}ê°œ ìƒì„±")
    
    return features


def merge_all_features(state_features: pd.DataFrame,
                       history_features: pd.DataFrame,
                       recency_features: pd.DataFrame,
                       cancel_features: pd.DataFrame) -> pd.DataFrame:
    """ëª¨ë“  í”¼ì²˜ ë³‘í•©"""
    print("\nğŸ”— í”¼ì²˜ ë³‘í•© ì¤‘...")
    
    # state ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©
    result = state_features.copy()
    
    result = result.merge(history_features, on='msno', how='left')
    result = result.merge(recency_features, on='msno', how='left')
    result = result.merge(cancel_features, on='msno', how='left')
    
    # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
    result = result.fillna(0)
    
    # Inf ì²˜ë¦¬
    result = result.replace([np.inf, -np.inf], 0)
    
    print(f"  âœ“ ë³‘í•© ì™„ë£Œ: {result.shape}")
    
    return result


def sanity_check(df: pd.DataFrame) -> None:
    """ì§‘ê³„ ê²°ê³¼ ê²€ì¦"""
    
    print("\nğŸ” Sanity Check...")
    print(f"  Shape: {df.shape}")
    print(f"  ê³ ìœ  msno: {df['msno'].nunique():,}")
    print(f"  ì¤‘ë³µ msno: {df['msno'].duplicated().sum()}")
    print(f"  ê²°ì¸¡ì¹˜: {df.isnull().sum().sum()}")
    
    # ì£¼ìš” í”¼ì²˜ í†µê³„
    print("\n  ì£¼ìš” í”¼ì²˜ í†µê³„:")
    key_features = ['days_since_last_payment', 'is_auto_renew_last', 'days_to_expire', 
                    'total_payment_count', 'has_cancelled']
    
    for feat in key_features:
        if feat in df.columns:
            print(f"    {feat}: mean={df[feat].mean():.2f}, std={df[feat].std():.2f}")


def run_aggregation_pipeline(data_dir: Path = DATA_DIR,
                             save: bool = True) -> pd.DataFrame:
    """ì „ì²´ ì§‘ê³„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
    
    print("=" * 60)
    print("ğŸš€ Transactions ì§‘ê³„ íŒŒì´í”„ë¼ì¸ (ìƒíƒœ + ëˆ„ì )")
    print("=" * 60)
    print(f"ê¸°ì¤€ ì‹œì  (T): {T.strftime('%Y-%m-%d')}")
    
    # 1. ë°ì´í„° ë¡œë“œ
    transactions = load_transactions(data_dir)
    
    # 2. ìƒíƒœ ê¸°ë°˜ í”¼ì²˜
    state_features = create_state_features(transactions)
    
    # 3. ëˆ„ì  íˆìŠ¤í† ë¦¬ í”¼ì²˜
    history_features = create_history_features(transactions)
    
    # 4. Recency í”¼ì²˜
    recency_features = create_recency_features(transactions)
    
    # 5. ì·¨ì†Œ ê´€ë ¨ í”¼ì²˜
    cancel_features = create_cancel_features(transactions)
    
    # 6. ë³‘í•©
    agg_df = merge_all_features(state_features, history_features, 
                                 recency_features, cancel_features)
    
    # 7. Sanity Check
    sanity_check(agg_df)
    
    # 8. ì €ì¥ (Parquet + PyArrow)
    if save:
        output_path = data_dir / 'transactions_aggregated_ldh.parquet'
        agg_df.to_parquet(output_path, engine='pyarrow', index=False)
        print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ (Parquet): {output_path}")
    
    print("\n" + "=" * 60)
    print("âœ… ì§‘ê³„ ì™„ë£Œ!")
    print("=" * 60)
    
    # í”¼ì²˜ ëª©ë¡ ì¶œë ¥
    print(f"\nğŸ“‹ ìƒì„±ëœ í”¼ì²˜ ({len(agg_df.columns)}ê°œ):")
    for i, col in enumerate(agg_df.columns):
        print(f"  {i+1:2d}. {col}")
    
    return agg_df


# ============================================
# ì‹¤í–‰
# ============================================
if __name__ == "__main__":
    agg_df = run_aggregation_pipeline()

